{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edelin/.conda/envs/trident_plot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "from inference_utils.pytorch_data_utils import __loadCLSembeddings__\n",
    "from inference_utils.pytorch_data_utils import __loadtrainingdf__\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold1_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val1_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold1_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train2_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold2_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val2_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold2_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train3_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold3_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val3_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold3_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train4_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold4_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val4_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold4_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train5_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold5_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val5_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold5_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train6_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold6_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val6_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold6_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train7_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold7_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val7_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold7_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train8_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold8_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val8_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold8_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train9_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold9_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val9_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold9_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train10_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold10_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val10_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold10_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train1_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold1_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val1_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold1_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train2_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold2_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val2_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold2_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train3_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold3_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val3_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold3_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train4_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold4_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val4_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold4_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train5_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold5_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val5_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold5_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train6_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold6_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val6_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold6_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train7_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold7_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val7_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold7_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train8_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold8_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val8_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold8_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train9_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold9_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val9_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold9_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train10_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold10_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val10_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold10_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=pd.merge(train1_data,train1_emb,on='SMILES_Canonical_RDKit')\n",
    "train2=pd.merge(train2_data,train2_emb,on='SMILES_Canonical_RDKit')\n",
    "train3=pd.merge(train3_data,train3_emb,on='SMILES_Canonical_RDKit')\n",
    "train4=pd.merge(train4_data,train4_emb,on='SMILES_Canonical_RDKit')\n",
    "train5=pd.merge(train5_data,train5_emb,on='SMILES_Canonical_RDKit')\n",
    "train6=pd.merge(train6_data,train6_emb,on='SMILES_Canonical_RDKit')\n",
    "train7=pd.merge(train7_data,train7_emb,on='SMILES_Canonical_RDKit')\n",
    "train8=pd.merge(train8_data,train8_emb,on='SMILES_Canonical_RDKit')\n",
    "train9=pd.merge(train9_data,train9_emb,on='SMILES_Canonical_RDKit')\n",
    "train10=pd.merge(train10_data,train10_emb,on='SMILES_Canonical_RDKit')\n",
    "\n",
    "val1=pd.merge(val1_data,val1_emb,on='SMILES_Canonical_RDKit')\n",
    "val2=pd.merge(val2_data,val2_emb,on='SMILES_Canonical_RDKit')\n",
    "val3=pd.merge(val3_data,val3_emb,on='SMILES_Canonical_RDKit')\n",
    "val4=pd.merge(val4_data,val4_emb,on='SMILES_Canonical_RDKit')\n",
    "val5=pd.merge(val5_data,val5_emb,on='SMILES_Canonical_RDKit')\n",
    "val6=pd.merge(val6_data,val6_emb,on='SMILES_Canonical_RDKit')\n",
    "val7=pd.merge(val7_data,val7_emb,on='SMILES_Canonical_RDKit')\n",
    "val8=pd.merge(val8_data,val8_emb,on='SMILES_Canonical_RDKit')\n",
    "val9=pd.merge(val9_data,val9_emb,on='SMILES_Canonical_RDKit')\n",
    "val10=pd.merge(val10_data,val10_emb,on='SMILES_Canonical_RDKit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Put together for easier handling\n",
    "dataframes = {\n",
    "    \"train\": [train1, train2, train3, train4, train5, train6, train7, train8, train9, train10],\n",
    "    \"val\": [val1, val2, val3, val4, val5, val6, val7, val8, val9, val10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get residuals and L1 \n",
    "residuals = {\"train\": [], \"val\": []}\n",
    "L1 = {\"train\": [], \"val\": []}\n",
    "\n",
    "for key, df_list in dataframes.items():\n",
    "    for df in df_list:\n",
    "        df_residuals = df['labels'] - df['preds']\n",
    "        \n",
    "        L1_fold = np.abs(df_residuals)\n",
    "        \n",
    "        residuals[key].append(df_residuals)\n",
    "        L1[key].append(L1_fold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    dataframes['train'][i]['pred_L1_error']=L1['train'][i]\n",
    "    dataframes['val'][i]['pred_L1_error']=L1['val'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    embeddings_train_fold=np.asarray(dataframes['train'][i].CLS_embeddings.tolist(), dtype=np.float32)\n",
    "    embeddings_val_fold=np.asarray(dataframes['val'][i].CLS_embeddings.tolist(), dtype=np.float32)\n",
    "    dataframes['val'][i]['distance_to_training'] = np.nan\n",
    "\n",
    "    for j in range(len(embeddings_val_fold)):\n",
    "        embeddings_val_fold_current=embeddings_val_fold[j].reshape(1, -1)\n",
    "        similarity=cosine_similarity(embeddings_train_fold,embeddings_val_fold_current).mean()\n",
    "        dataframes['val'][i].at[j, 'distance_to_training'] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb=[dataframes['val'][0],dataframes['val'][1],dataframes['val'][2],dataframes['val'][3],dataframes['val'][4],dataframes['val'][5],dataframes['val'][6],dataframes['val'][7],dataframes['val'][8],dataframes['val'][9]]\n",
    "combined_df = pd.concat(comb, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_knn_with_cv(X_train, y_train, n_splits=10, k_values=[ 1,7,10,15,20,25]):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    best_k = None # set initial best k\n",
    "    best_mse = float('inf') #set initial best MSE \n",
    "    fold_mses = [] # for collecting the MSE of the folds\n",
    "    train_correlations_pearson = []\n",
    "    val_correlations_pearson = []\n",
    "    train_correlations_spearman = []\n",
    "    val_correlation_spearman = []\n",
    "\n",
    "    for k in k_values:\n",
    "        fold_mses_k = [] # collect MSE within folds\n",
    "        for train_idx, val_idx in kf.split(X_train):\n",
    "            X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx] # split the training data into train and val data\n",
    "            y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
    "            \n",
    "            # Train the kNN model\n",
    "            knn = KNeighborsRegressor(n_neighbors=k,weights='distance',metric='cosine')\n",
    "            knn.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "            # Predict and evaluate\n",
    "            y_val_pred = knn.predict(X_val_fold)\n",
    "            mse_val = mean_squared_error(y_val_fold, y_val_pred)\n",
    "            fold_mses_k.append(mse_val)\n",
    "\n",
    "            y_train_pred=knn.predict(X_train_fold)\n",
    "            # Compute Pearson correlation and spearman\n",
    "            train_corr_pearson = pearsonr(y_train_fold, y_train_pred)[0]\n",
    "            val_corr_pearson = pearsonr(y_val_fold, y_val_pred)[0]\n",
    "            train_corr_spearman=spearmanr(y_train_fold,y_train_pred)[0]\n",
    "            val_corr_spearman=spearmanr(y_val_fold,y_val_pred)[0]\n",
    "    \n",
    "            train_correlations_pearson.append(train_corr_pearson)\n",
    "            val_correlations_pearson.append(val_corr_pearson)\n",
    "            train_correlations_spearman.append(train_corr_spearman)\n",
    "            val_correlation_spearman.append(val_corr_spearman)\n",
    "\n",
    "        # Average MSE for this k-vlaue\n",
    "        avg_mse_k = np.mean(fold_mses_k)\n",
    "        print(f\"Average Validation MSE (inside train fold) for k={k}: {avg_mse_k:.3f}\")\n",
    "\n",
    "        # Track the best k-value for parameter choice\n",
    "        if avg_mse_k < best_mse:\n",
    "            best_mse = avg_mse_k\n",
    "            best_k = k\n",
    "        fold_mses.append(avg_mse_k)\n",
    "\n",
    "    print(f\"Best k: {best_k} with MSE: {best_mse:.3f}\")\n",
    "\n",
    "    # Refit the final model on the entire trainset with the best k-value\n",
    "    knn_final = KNeighborsRegressor(n_neighbors=best_k)\n",
    "    knn_final.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Average Training Correlation Pearson (inside train fold): {np.mean(train_correlations_pearson):.3f}\")\n",
    "    print(f\"Average Validation Correlation Pearson (inside train fold): {np.mean(val_correlations_pearson):.3f}\")\n",
    "    print(f\"Average Training Correlation Spearman (inside train fold): {np.mean(train_correlations_spearman):.3f}\")\n",
    "    print(f\"Average Validation Correlation Spearman (inside train fold): {np.mean(val_correlation_spearman):.3f}\")\n",
    "\n",
    "\n",
    "    return knn_final, best_k, fold_mses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_knn_model(knn_model,  X_train, y_train, X_val, y_val): \n",
    "\n",
    "    # Predict using the kNN model\n",
    "    y_train_pred = knn_model.predict(X_train)\n",
    "    y_val_pred = knn_model.predict(X_val)\n",
    "\n",
    "    # Calculate MSE\n",
    "    train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "    val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "    print(f\"Train MSE: {train_mse:.3f}\")\n",
    "    print(f\"Validation MSE: {val_mse:.3f}\")\n",
    "\n",
    "    return train_mse, val_mse, y_train_pred,y_val_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation MSE (inside train fold) for k=1: 0.660\n",
      "Average Validation MSE (inside train fold) for k=5: 0.407\n",
      "Average Validation MSE (inside train fold) for k=10: 0.382\n",
      "Average Validation MSE (inside train fold) for k=15: 0.376\n",
      "Average Validation MSE (inside train fold) for k=20: 0.372\n",
      "Average Validation MSE (inside train fold) for k=30: 0.368\n",
      "Average Validation MSE (inside train fold) for k=40: 0.364\n",
      "Average Validation MSE (inside train fold) for k=50: 0.362\n",
      "Average Validation MSE (inside train fold) for k=60: 0.361\n",
      "Average Validation MSE (inside train fold) for k=70: 0.361\n",
      "Average Validation MSE (inside train fold) for k=80: 0.360\n",
      "Average Validation MSE (inside train fold) for k=90: 0.360\n",
      "Average Validation MSE (inside train fold) for k=100: 0.360\n",
      "Average Validation MSE (inside train fold) for k=120: 0.359\n",
      "Average Validation MSE (inside train fold) for k=140: 0.358\n",
      "Average Validation MSE (inside train fold) for k=160: 0.358\n",
      "Average Validation MSE (inside train fold) for k=180: 0.359\n",
      "Average Validation MSE (inside train fold) for k=200: 0.359\n",
      "Average Validation MSE (inside train fold) for k=220: 0.359\n",
      "Average Validation MSE (inside train fold) for k=240: 0.359\n",
      "Average Validation MSE (inside train fold) for k=260: 0.358\n",
      "Average Validation MSE (inside train fold) for k=280: 0.358\n",
      "Average Validation MSE (inside train fold) for k=300: 0.359\n",
      "Best k: 160 with MSE: 0.358\n",
      "Average Training Correlation Pearson (inside train fold): 1.000\n",
      "Average Validation Correlation Pearson (inside train fold): 0.219\n",
      "Average Training Correlation Spearman (inside train fold): 1.000\n",
      "Average Validation Correlation Spearman (inside train fold): 0.182\n",
      "Train MSE: 0.364\n",
      "Validation MSE: 0.217\n",
      "Train MSE small error: 0.3641712 Val MSE (outside of train fold) small error: 0.21673568\n",
      "Train MSE: 0.364\n",
      "Validation MSE: 3.863\n",
      "Train MSE big error: 0.3641712 Val MSE (outside of train fold) big error: 3.8634408\n"
     ]
    }
   ],
   "source": [
    "embedding_scaler=StandardScaler()\n",
    "closeness_scaler=StandardScaler()\n",
    "embeddings = np.asarray(combined_df.CLS_embeddings.tolist(),dtype=np.float32) # train embeddings fold i\n",
    "embeddings_scaled=embedding_scaler.fit_transform(embeddings)\n",
    "closeness=combined_df[['distance_to_training']].values\n",
    "closeness_scaled=closeness_scaler.fit_transform(closeness)\n",
    "X=np.hstack([embeddings_scaled,closeness_scaled] )  # Add closeness as a feature\n",
    "\n",
    "labels = np.asarray(combined_df.pred_L1_error.tolist(),dtype=np.float32)  # train errors fold i\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,          # Features or the entire DataFrame\n",
    "    labels,        # Target or None\n",
    "    test_size=0.2, # Proportion of the data to include in the test split\n",
    "    random_state=42, # Random seed for reproducibility\n",
    "    shuffle=True   # Shuffle the data before splitting (default is True)\n",
    ")\n",
    "# divide the testing data into small and big errors\n",
    "small_error = y_test < 2\n",
    "big_error = y_test >= 2\n",
    "X_test_small=X_test[small_error]\n",
    "y_test_small=y_test[small_error]\n",
    "X_test_big=X_test[big_error]\n",
    "y_test_big=y_test[big_error]\n",
    "\n",
    "knn_model, best_k, fold_mses = train_knn_with_cv(X_train, y_train, k_values=[ 1,5,10,15,20,30,40,50,60,70,80,90,100,120,140,160,180,200,220,240,260,280,300]) #scaler_combined,\n",
    "    # Evaluate on validation \n",
    "train_mse_small, val_mse_small,y_train_pred_small,y_val_pred_small = evaluate_knn_model(knn_model, X_train, y_train, X_test_small, y_test_small) \n",
    "print('Train MSE small error:', train_mse_small,'Val MSE (outside of train fold) small error:',val_mse_small)\n",
    "\n",
    "train_mse_big, val_mse_big,y_train_pred_big,y_val_pred_big = evaluate_knn_model(knn_model, X_train, y_train, X_test_big, y_test_big) \n",
    "print('Train MSE big error:', train_mse_big,'Val MSE (outside of train fold) big error:',val_mse_big)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation pearson small error: 0.17219976\n",
      "Correlation pearson big error: 0.32054102\n",
      "Correlation spearman small error: 0.16818801638462735\n",
      "Correlation spearman big error: 0.23596059113300488\n"
     ]
    }
   ],
   "source": [
    "corr_small_p=pearsonr(y_test_small,y_val_pred_small)[0]\n",
    "corr_big_p=pearsonr(y_test_big,y_val_pred_big)[0]\n",
    "corr_small_s=spearmanr(y_test_small,y_val_pred_small)[0]\n",
    "corr_big_s=spearmanr(y_test_big,y_val_pred_big)[0]\n",
    "print('Correlation pearson small error:',corr_small_p)\n",
    "print('Correlation pearson big error:',corr_big_p)\n",
    "print('Correlation spearman small error:',corr_small_s)\n",
    "print('Correlation spearman big error:',corr_big_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trident_plot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
