{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A naive KNN where the error value is predicted by looking at the values of the k-nearest neighbors and assigned from their value (mean of the closest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import  cosine_similarity\n",
    "from inference_utils.pytorch_data_utils import __loadCLSembeddings__\n",
    "from inference_utils.pytorch_data_utils import __loadtrainingdf__\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold1_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val1_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold1_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train2_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold2_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val2_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold2_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train3_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold3_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val3_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold3_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train4_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold4_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val4_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold4_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train5_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold5_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val5_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold5_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train6_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold6_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val6_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold6_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train7_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold7_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val7_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold7_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train8_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold8_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val8_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold8_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train9_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold9_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val9_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold9_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n",
    "train10_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold10_seed41_training_results_final_epoch.pkl.zip',compression='zip')\n",
    "val10_data = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/without_duration/fold10_seed41_validation_results_final_epoch.pkl.zip',compression='zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train1_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold1_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val1_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold1_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train2_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold2_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val2_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold2_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train3_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold3_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val3_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold3_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train4_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold4_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val4_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold4_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train5_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold5_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val5_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold5_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train6_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold6_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val6_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold6_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train7_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold7_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val7_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold7_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train8_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold8_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val8_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold8_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train9_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold9_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val9_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold9_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "train10_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold10_seed41_training_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n",
    "val10_emb = pd.read_pickle('../../../../storage/shared/master_thesis_TRIDENT/TRIDENT_for_Elin/TRIDENT_fish_EC50_10foldCV_35epochs_for_Elin/fold10_seed41_validation_SMILES_to_CLS_final_epoch.pkl.zip',compression='zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1=pd.merge(train1_data,train1_emb,on='SMILES_Canonical_RDKit')\n",
    "train2=pd.merge(train2_data,train2_emb,on='SMILES_Canonical_RDKit')\n",
    "train3=pd.merge(train3_data,train3_emb,on='SMILES_Canonical_RDKit')\n",
    "train4=pd.merge(train4_data,train4_emb,on='SMILES_Canonical_RDKit')\n",
    "train5=pd.merge(train5_data,train5_emb,on='SMILES_Canonical_RDKit')\n",
    "train6=pd.merge(train6_data,train6_emb,on='SMILES_Canonical_RDKit')\n",
    "train7=pd.merge(train7_data,train7_emb,on='SMILES_Canonical_RDKit')\n",
    "train8=pd.merge(train8_data,train8_emb,on='SMILES_Canonical_RDKit')\n",
    "train9=pd.merge(train9_data,train9_emb,on='SMILES_Canonical_RDKit')\n",
    "train10=pd.merge(train10_data,train10_emb,on='SMILES_Canonical_RDKit')\n",
    "\n",
    "val1=pd.merge(val1_data,val1_emb,on='SMILES_Canonical_RDKit')\n",
    "val2=pd.merge(val2_data,val2_emb,on='SMILES_Canonical_RDKit')\n",
    "val3=pd.merge(val3_data,val3_emb,on='SMILES_Canonical_RDKit')\n",
    "val4=pd.merge(val4_data,val4_emb,on='SMILES_Canonical_RDKit')\n",
    "val5=pd.merge(val5_data,val5_emb,on='SMILES_Canonical_RDKit')\n",
    "val6=pd.merge(val6_data,val6_emb,on='SMILES_Canonical_RDKit')\n",
    "val7=pd.merge(val7_data,val7_emb,on='SMILES_Canonical_RDKit')\n",
    "val8=pd.merge(val8_data,val8_emb,on='SMILES_Canonical_RDKit')\n",
    "val9=pd.merge(val9_data,val9_emb,on='SMILES_Canonical_RDKit')\n",
    "val10=pd.merge(val10_data,val10_emb,on='SMILES_Canonical_RDKit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Put together for easier handling\n",
    "dataframes = {\n",
    "    \"train\": [train1, train2, train3, train4, train5, train6, train7, train8, train9, train10],\n",
    "    \"val\": [val1, val2, val3, val4, val5, val6, val7, val8, val9, val10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get L1 \n",
    "residuals = {\"train\": [], \"val\": []}\n",
    "L1 = {\"train\": [], \"val\": []}\n",
    "\n",
    "for key, df_list in dataframes.items():\n",
    "    for df in df_list:\n",
    "        df_residuals = df['labels'] - df['preds']\n",
    "        \n",
    "        L1_fold = np.abs(df_residuals)\n",
    "        \n",
    "        residuals[key].append(df_residuals)\n",
    "        L1[key].append(L1_fold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    dataframes['train'][i]['pred_L1_error']=L1['train'][i]\n",
    "    dataframes['val'][i]['pred_L1_error']=L1['val'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    embeddings_train_fold=np.asarray(dataframes['train'][i].CLS_embeddings.tolist(), dtype=np.float32)\n",
    "    embeddings_val_fold=np.asarray(dataframes['val'][i].CLS_embeddings.tolist(), dtype=np.float32)\n",
    "    dataframes['val'][i]['distance_to_training'] = np.nan\n",
    "\n",
    "    for j in range(len(embeddings_val_fold)):\n",
    "        embeddings_val_fold_current=embeddings_val_fold[j].reshape(1, -1)\n",
    "        similarity=cosine_similarity(embeddings_train_fold,embeddings_val_fold_current).mean()\n",
    "        dataframes['val'][i].at[j, 'distance_to_training'] = similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb=[dataframes['val'][0],dataframes['val'][1],dataframes['val'][2],dataframes['val'][3],dataframes['val'][4],dataframes['val'][5],dataframes['val'][6],dataframes['val'][7],dataframes['val'][8],dataframes['val'][9]]\n",
    "combined_df = pd.concat(comb, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_scaler=StandardScaler()\n",
    "closeness_scaler=StandardScaler()\n",
    "embeddings = np.asarray(combined_df.CLS_embeddings.tolist(),dtype=np.float32) # train embeddings fold i\n",
    "embeddings_scaled=embedding_scaler.fit_transform(embeddings)\n",
    "closeness=combined_df[['distance_to_training']].values\n",
    "closeness_scaled=closeness_scaler.fit_transform(closeness)\n",
    "X=np.hstack([embeddings_scaled,closeness_scaled] )  # Add closeness as a feature\n",
    "\n",
    "labels = np.asarray(combined_df.pred_L1_error.tolist(),dtype=np.float32)  # train errors fold i\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,          # Features or the entire DataFrame\n",
    "    labels,        \n",
    "    test_size=0.2, # Proportion of the data to include in the test split\n",
    "    random_state=42, # Random seed for reproducibility\n",
    "    shuffle=True   # Shuffle the data before splitting \n",
    ")\n",
    "# split the test data into small and big error\n",
    "small_error = y_test < 2\n",
    "big_error = y_test >= 2\n",
    "X_test_small=X_test[small_error]\n",
    "y_test_small=y_test[small_error]\n",
    "X_test_big=X_test[big_error]\n",
    "y_test_big=y_test[big_error]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating k=1\n",
      "Evaluating k=5\n",
      "Evaluating k=10\n",
      "Evaluating k=20\n",
      "Evaluating k=30\n",
      "Evaluating k=40\n",
      "Evaluating k=50\n",
      "Evaluating k=60\n",
      "Evaluating k=70\n",
      "Evaluating k=80\n",
      "Evaluating k=90\n",
      "Evaluating k=100\n",
      "Evaluating k=120\n",
      "Evaluating k=140\n",
      "Evaluating k=160\n",
      "Evaluating k=180\n",
      "Evaluating k=200\n",
      "Evaluating k=220\n",
      "Evaluating k=240\n",
      "Evaluating k=260\n",
      "Evaluating k=280\n",
      "Evaluating k=300\n",
      "Best k: 90\n",
      "k=1, Metrics: {'training_train_MSE': np.float32(2.1598341e-06), 'training_val_MSE': np.float32(0.6573933), 'training_train_corr': np.float32(0.9999971), 'training_val_corr': np.float32(0.10943854)}\n",
      "k=5, Metrics: {'training_train_MSE': np.float32(0.2623127), 'training_val_MSE': np.float32(0.46683896), 'training_train_corr': np.float32(0.54083663), 'training_val_corr': np.float32(0.13297543)}\n",
      "k=10, Metrics: {'training_train_MSE': np.float32(0.30565092), 'training_val_MSE': np.float32(0.43531662), 'training_train_corr': np.float32(0.41697386), 'training_val_corr': np.float32(0.17306753)}\n",
      "k=20, Metrics: {'training_train_MSE': np.float32(0.32762122), 'training_val_MSE': np.float32(0.4328602), 'training_train_corr': np.float32(0.33822197), 'training_val_corr': np.float32(0.15370996)}\n",
      "k=30, Metrics: {'training_train_MSE': np.float32(0.33404452), 'training_val_MSE': np.float32(0.41955343), 'training_train_corr': np.float32(0.3105274), 'training_val_corr': np.float32(0.19603455)}\n",
      "k=40, Metrics: {'training_train_MSE': np.float32(0.33706328), 'training_val_MSE': np.float32(0.4178286), 'training_train_corr': np.float32(0.29812184), 'training_val_corr': np.float32(0.19974026)}\n",
      "k=50, Metrics: {'training_train_MSE': np.float32(0.3386844), 'training_val_MSE': np.float32(0.42054018), 'training_train_corr': np.float32(0.29192507), 'training_val_corr': np.float32(0.18168156)}\n",
      "k=60, Metrics: {'training_train_MSE': np.float32(0.34025806), 'training_val_MSE': np.float32(0.41990936), 'training_train_corr': np.float32(0.28677845), 'training_val_corr': np.float32(0.18652514)}\n",
      "k=70, Metrics: {'training_train_MSE': np.float32(0.34059966), 'training_val_MSE': np.float32(0.41835123), 'training_train_corr': np.float32(0.28708753), 'training_val_corr': np.float32(0.19418766)}\n",
      "k=80, Metrics: {'training_train_MSE': np.float32(0.34274697), 'training_val_MSE': np.float32(0.41574845), 'training_train_corr': np.float32(0.27457005), 'training_val_corr': np.float32(0.20953286)}\n",
      "k=90, Metrics: {'training_train_MSE': np.float32(0.34382546), 'training_val_MSE': np.float32(0.4152569), 'training_train_corr': np.float32(0.26854837), 'training_val_corr': np.float32(0.21261387)}\n",
      "k=100, Metrics: {'training_train_MSE': np.float32(0.34364682), 'training_val_MSE': np.float32(0.41603386), 'training_train_corr': np.float32(0.27042586), 'training_val_corr': np.float32(0.20816806)}\n",
      "k=120, Metrics: {'training_train_MSE': np.float32(0.34467676), 'training_val_MSE': np.float32(0.41757146), 'training_train_corr': np.float32(0.2644001), 'training_val_corr': np.float32(0.19571337)}\n",
      "k=140, Metrics: {'training_train_MSE': np.float32(0.34537166), 'training_val_MSE': np.float32(0.41870522), 'training_train_corr': np.float32(0.25935397), 'training_val_corr': np.float32(0.18474822)}\n",
      "k=160, Metrics: {'training_train_MSE': np.float32(0.3467105), 'training_val_MSE': np.float32(0.41945216), 'training_train_corr': np.float32(0.24839783), 'training_val_corr': np.float32(0.17639649)}\n",
      "k=180, Metrics: {'training_train_MSE': np.float32(0.347602), 'training_val_MSE': np.float32(0.4194214), 'training_train_corr': np.float32(0.24175668), 'training_val_corr': np.float32(0.17393227)}\n",
      "k=200, Metrics: {'training_train_MSE': np.float32(0.34789932), 'training_val_MSE': np.float32(0.41845956), 'training_train_corr': np.float32(0.23829395), 'training_val_corr': np.float32(0.17872885)}\n",
      "k=220, Metrics: {'training_train_MSE': np.float32(0.34785208), 'training_val_MSE': np.float32(0.41878095), 'training_train_corr': np.float32(0.23754874), 'training_val_corr': np.float32(0.17479803)}\n",
      "k=240, Metrics: {'training_train_MSE': np.float32(0.34806326), 'training_val_MSE': np.float32(0.41789937), 'training_train_corr': np.float32(0.23542142), 'training_val_corr': np.float32(0.18011585)}\n",
      "k=260, Metrics: {'training_train_MSE': np.float32(0.34878936), 'training_val_MSE': np.float32(0.41842178), 'training_train_corr': np.float32(0.22891995), 'training_val_corr': np.float32(0.17455222)}\n",
      "k=280, Metrics: {'training_train_MSE': np.float32(0.34887868), 'training_val_MSE': np.float32(0.41887492), 'training_train_corr': np.float32(0.22732416), 'training_val_corr': np.float32(0.16989984)}\n",
      "k=300, Metrics: {'training_train_MSE': np.float32(0.3490955), 'training_val_MSE': np.float32(0.4183174), 'training_train_corr': np.float32(0.2247228), 'training_val_corr': np.float32(0.17263015)}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def naiveKNN(training_embeddings,training_values, X, k):\n",
    "\n",
    "    training_embeddings = np.array(training_embeddings)\n",
    "    training_values = np.array(training_values)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    nn = NearestNeighbors(n_neighbors=k, metric=\"cosine\")\n",
    "    nn.fit(training_embeddings)\n",
    "    \n",
    "    # Find the indices of k nearest neighbors for all input embeddings\n",
    "    distances, indices = nn.kneighbors(X)\n",
    "    \n",
    "    # Compute the mean of y -train values for the k-nearest neighbors\n",
    "    mean_values = np.array([np.mean(training_values[neighbor_indices]) for neighbor_indices in indices])\n",
    "\n",
    "    return mean_values\n",
    "\n",
    "# Grid Search of the k-values\n",
    "def grid_search_kNN(X_train, y_train, k_values, n_jobs=-1):\n",
    "    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    def evaluate_training(k):\n",
    "        naive_val_pred = naiveKNN(X_train_split,y_train_split,X_test_split, k)\n",
    "        naive_train_pred = naiveKNN(X_train_split,  y_train_split,X_train_split, k)\n",
    "\n",
    "        training_val_MSE = mean_squared_error(y_test_split, naive_val_pred)\n",
    "        training_train_MSE = mean_squared_error(y_train_split, naive_train_pred)\n",
    "\n",
    "\n",
    "        val_corr = pearsonr(y_test_split, naive_val_pred)[0] if np.std(naive_val_pred) > 0 else 0\n",
    "        train_corr = pearsonr(y_train_split, naive_train_pred)[0] if np.std(naive_train_pred) > 0 else 0\n",
    "\n",
    "\n",
    "        return training_train_MSE, training_val_MSE, train_corr, val_corr\n",
    "\n",
    "\n",
    "    # evaluation during training\n",
    "    results = {}\n",
    "    for k in k_values:\n",
    "        #print(f\"Evaluating k={k}\")\n",
    "        train_MSE, val_MSE, train_corr, val_corr = evaluate_training(k)\n",
    "        results[k] = {\n",
    "        \"training_train_MSE\": train_MSE,\n",
    "        \"training_val_MSE\": val_MSE,\n",
    "        \"training_train_corr\": train_corr,\n",
    "        \"training_val_corr\": val_corr,\n",
    "        }\n",
    "\n",
    "\n",
    "    # Find the best k based on validation MSE\n",
    "    best_k = min(results, key=lambda x: results[x][\"training_val_MSE\"])\n",
    "    return best_k, results\n",
    "\n",
    "k_values = [1,5, 10, 20, 30, 40,50,60,70,80,90,100,120,140,160,180,200,220,240,260,280,300]\n",
    "best_k, gridsearch_results = grid_search_kNN(X_train=X_train, y_train=y_train, k_values=k_values)\n",
    "\n",
    "print(f\"Best k: {best_k}\")\n",
    "for k, corr_and_mse in gridsearch_results.items():\n",
    "    print(f\"k={k}, Metrics: {corr_and_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_small=naiveKNN(X_train,y_train,X_test_small,best_k)\n",
    "y_val_pred_big=naiveKNN(X_train,y_train,X_test_big,best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best k-value: 90\n",
      "MSE small errors: 0.21854526\n",
      "MSE big errors: 3.7929041\n"
     ]
    }
   ],
   "source": [
    "mse_small=mean_squared_error(y_test_small,y_val_pred_small)\n",
    "mse_big=mean_squared_error(y_test_big,y_val_pred_big)\n",
    "print('best k-value:',best_k)\n",
    "print('MSE small errors:',mse_small)\n",
    "print('MSE big errors:',mse_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation pearson small error: 0.1696001\n",
      "Correlation pearson big error: 0.30295858\n",
      "Correlation spearman small error: 0.1840172791947062\n",
      "Correlation spearman big error: 0.23546798029556643\n"
     ]
    }
   ],
   "source": [
    "corr_small_p=pearsonr(y_test_small,y_val_pred_small)[0]\n",
    "corr_big_p=pearsonr(y_test_big,y_val_pred_big)[0]\n",
    "corr_small_s=spearmanr(y_test_small,y_val_pred_small)[0]\n",
    "corr_big_s=spearmanr(y_test_big,y_val_pred_big)[0]\n",
    "print('Correlation pearson small error:',corr_small_p)\n",
    "print('Correlation pearson big error:',corr_big_p)\n",
    "print('Correlation spearman small error:',corr_small_s)\n",
    "print('Correlation spearman big error:',corr_big_s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trident_plot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
